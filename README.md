# 机器学习个人笔记（更新中）
**目录**

[1.梯度 2](#_Toc2930_WPSOffice_Level1 )

[1.1.梯度的概念 2](#_Toc6055_WPSOffice_Level2 )

[1.2.梯度下降算法的实现 2](#_Toc16427_WPSOffice_Level2 )

[1.3.梯度下降树 4](#_Toc21947_WPSOffice_Level2 )

[2.决策树 5](#_Toc6055_WPSOffice_Level1 )

[2.1.ID3决策树学习算法 5](#_Toc24483_WPSOffice_Level2 )

[2.2.C4.5决策树算法 5](#_Toc14932_WPSOffice_Level2 )

[2.3.基尼指数CART决策树算法 6](#_Toc30843_WPSOffice_Level2 )

[2.4.剪枝处理 6](#_Toc27909_WPSOffice_Level2 )

[2.4.1.预剪枝  6](#_Toc6055_WPSOffice_Level3 )

[2.4.2.后剪枝 6](#_Toc16427_WPSOffice_Level3 )

[3.偏差与方差 6](#_Toc16427_WPSOffice_Level1 )

[3.1.导致偏差和方差的原因 7](#_Toc30040_WPSOffice_Level2 )

[3.2.深度学习中的偏差与方差 7](#_Toc4543_WPSOffice_Level2 )

[4.生成模型与判别模型 7](#_Toc21947_WPSOffice_Level1 )

[4.1.两者之间的联系 8](#_Toc9945_WPSOffice_Level2 )

[4.2.常见模型 8](#_Toc18763_WPSOffice_Level2 )

[5.先验概率与后验概率 8](#_Toc24483_WPSOffice_Level1 )

[6.Bagging vs Boosting 9](#_Toc14932_WPSOffice_Level1 )

[7.信息熵、KL 散度（相对熵）与交叉熵 9](#_Toc30843_WPSOffice_Level1 )

[8.一个完整的机器学习项目流程 10](#_Toc27909_WPSOffice_Level1 )


